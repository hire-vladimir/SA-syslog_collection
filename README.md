[![PayPal donate button](https://img.shields.io/badge/paypal-donate-yellow.svg)](https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=7HYTU6BWTGQPE "Donate once-off to this project using Paypal")

# Welcome
While Splunk can listen for syslog data directly, for large implementation is it recommended to stand up dedicated collection infrastructure with a Universal forwarder for data forwarding to the indexer tier.

This app provides monitoring dashboards and sample configuration for two popular collection mechanisms based on:

* [rsyslog](http://www.rsyslog.com/)
* [syslog-ng](https://www.balabit.com/network-security/syslog-ng)

This project is hosted on GitHub, see https://github.com/hire-vladimir/SA-syslog_collection

# Install
App needs to be present on search heads and indexers (defines indexes.conf and index time operations). In future releases, will be split to SA and TA.

**Did you know:** Splunk allows you to install *.zip* based apps via the UI, meaning, you are able to install *master.zip* generated by GitHub.

# Getting Started
When deploying dedicated syslog infrastructure, general workflow occurs as follows:

1. syslog daemon listens for TCP or UDP syslog traffic, writes categorized information to a file
2. Splunk Universal Forwarder monitors said file, sends data to the indexer tier

Optionally, for high availability (HA) and robustness purposes, it is recommended to place a load balancer in front of syslog listeners with n+1 configuration, such that if one listener goes down, little to no data is lost. Secondary benefit of this is scalability and growth purposes, no need to manually load balance the configured devices to specific nodes.

## Screenshot
![SA-syslog_collection overview](https://raw.githubusercontent.com/hire-vladimir/SA-syslog_collection/master/static/screenshot.png)

## System requirements
The app was tested on Splunk 6.3+ on CentOS Linux 7.1. *rsyslog* and *syslog-ng* are supported on linux based operating systems.

## Configuration
1. Read the documentation provided with the app, install app
2. Make a decision on syslog daemon that will be used in your environment, read product specific deployment and configuration instructions:
  * [rsyslog](https://github.com/hire-vladimir/SA-syslog_collection/rsyslog.md)
  * [syslog-ng](https://github.com/hire-vladimir/SA-syslog_collection/static/syslog-ng.md)
3. Configure Universal forwarders on the dedicated syslog machines to read output files. See *Universal forwarder configuration* for additional insights
4. Use the app to view environment metrics

### Universal forwarder configuration
There are few *nice to have* settings that can be made on the UF's to get additional metrics and data points

* `inputs.conf` should be structures per example below, the classification work done at the syslog level really makes things simple!
```
# Cisco SourceFire data
[monitor:///var/log/remote/sourcefire/*/*.log]
host_segment = 5
sourcetype = cisco:sourcefire:defencecenter:syslog
index = sourcefire
#ignoreOlderThan = 7d
disabled = true
#
# specialPort data
[monitor:///var/log/remote/specialPort/*/*.log]
host_segment = 5
sourcetype = specialPort:syslog
index = my_special_index
#ignoreOlderThan = 7d
disabled = true
```
* Ensure UF `outputs.conf` has *forceTimebasedAutoLB* set to true, this will ensure data will evenly distribute across all available indexers and does not stick to any particular one
```
[tcpout]
forceTimebasedAutoLB = true
```
* Ensure UF `limits.conf` is not being throttled to ensure minimal latency
```
[thruput]
maxKBps = 0
```
* Update *_introspection* of cpu/memory metrics more frequently then the default of 10 minutes, in `/opt/splunkforwarder/etc/apps/introspection_generator_addon/local` set
```
[introspection:generator:resource_usage]
collectionPeriodInSecs = 60
```
* Have UF create metadata field `splunk_syslog_server`, this is extremely helpful in order to determine if syslog is evenly distributed across nodes. In `/opt/splunkforwarder/etc/system/local/inputs.conf` add following section, substituting `<HOSTNAME>` with the instance name. **Note:** when setting values at *default* stanza, this setting will be applied to ANY input, meaning, if UF is not dedicated to syslog, consider substituting to specific inputs.
```
[default]
_meta = splunk_syslog_server::<HOSTNAME>
```
To make this field indexed for further reporting, on the indexers add `/opt/splunk/etc/system/local/fields.conf`
```
[splunk_syslog_server]
INDEXED = true
```

### Data collection
App collects output of **netstat -stu** every 60 seconds to monitor packet loss and errors. Future plan includes gathering of syslog specific metrics, such as impstats

# Troubleshooting
When running into issues, consider the following:
* When syslog daemon is not functioning as expected, or no data is collected, check `/var/log/messages` for clues
  * Temporarily start *syslog-ng* in debug mode `syslog-ng -Fevd`
  * Temporarily start *rsyslog* in debug mode `rsyslogd -n`
* Ensure local firewall has appropriate rules in place or stopped
* Ensure appropriate ports are open and listening, try `netstat -an | grep 514`, or substituting ports as needed
* Ensure *selinux* is tuned or disabled, do you see denies in `cat /var/log/audit/audit.log | grep syslog | grep denied`
  * Particularly prevalent when listening to ports outside of 514 or writing log data outside of */var/log/*
  * To see current state, run `sestatus | grep Current` enforcing indicates selinux is enabled
* To validate data is streaming in, or specific format is used, try `tcpdump -Ani any "port 514 and host 10.200.1.1"`

# Testing
[sysloggen](https://subversion.assembla.com/svn/logzilla/scripts/contrib/sysloggen/) utility is great at generating syslog traffic to ensure infrastructure is functioning as expected. Tool could also be used to run load and loss tests.

Syntax:
```
root@x /t/syslog# ./sysloggen --help


LogZilla(tm) Syslog Generation Tool v1.0
This tool is free for personal (home) use only.
Please contact sales@logzilla.pro for permission to use elsewhere.

Usage: sysloggen --dest <target1> [-d <target2>, ... ] --file <raw_messages_file> [Options]

Options:
  -d <ip/unix_socket>, --dest <ip/unix_socket>
     IP address or Unix Domain socket name (when used together with the --unix option)
  -f <raw_messages_file>, --file <raw_messages_file>
      File name, file should contain preformatted syslog messages
  -s, --file_source <ip>   Spoof file_source IP address using UDP transport  -i, --inet   Use the TCP (by default) or UDP (when used together with the --dgram option)
  -u, --unix   Use a UNIX domain socket to send the messages to the target
  -S, --stream Use a stream socket (TCP or unix-stream) to send the messages to the target
  -D, --dgram  Use datagram socket (UDP or unix-dgram) to send the messages to the target
  -r, <messages/second>, --rate <messages/second>
      The number of messages generated per second, otherwise - max possible
  -n <messages>, --number <messages>
      Limit the number of messages to be sent
  -l, --loop   Read the file specified in --file options in loop
  -m <size>, --max-msg-size <size> Messages will be truncated if bigger then <size>
  -h, --help   Print this message and exit
  -v, --verbose    Make verbose output

Example:
Send 1 Million syslog events (loaded from the file "sample_cisco_ios.syslog") to 192.168.1.1 at a rate of 20k events/sec
./sysloggen -d 192.168.1.1 -f sample_cisco_ios.syslog -n 1000000 -r 20000 -l
root@x /t/syslog#
```

# Legal
* *rsyslog* is a registered trademark of RSYSLOG
* *syslog-ng* is a registered trademark of BalaBit IT Security
* *Splunk* is a registered trademark of Splunk, Inc.
